{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/zzc/code/private/RS_SISTR')\n",
    "from train import *\n",
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "from layers.models import IRSeg as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# load model options\n",
    "with open('../option/RSITMD_IRSeg.yaml', 'r') as handle:\n",
    "    # options = yaml.load(handle)\n",
    "    options = yaml.load(handle, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Seg-IR check model...\n"
     ]
    }
   ],
   "source": [
    "vocab = deserialize_vocab('../data/vocab/rsitmd_splits_vocab.json')\n",
    "check_loader = data.get_precomp_loader( 'check', vocab,\n",
    "                                    options['dataset']['batch_size'], True, options['dataset']['workers'], opt=options)\n",
    "vocab_word = sorted(vocab.word2idx.items(), key=lambda x: x[1], reverse=False)\n",
    "vocab_word = [tup[0] for tup in vocab_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply backbone resnet-18...\n",
      "Warning: 56/930911 words are not in dictionary, thus set UNK\n"
     ]
    }
   ],
   "source": [
    "model = models.factory(options['model'],\n",
    "                        vocab_word,\n",
    "                        cuda=True, \n",
    "                        data_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seg_loss': tensor(0.1456, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(223.0688, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "{'Seg_loss': tensor(0.1463, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(220.3479, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "{'Seg_loss': tensor(0.1470, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(220.4619, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "{'Seg_loss': tensor(0.1459, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(219.8684, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "{'Seg_loss': tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(222.5589, device='cuda:0', grad_fn=<AddBackward0>)}\n",
      "{'Seg_loss': tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>), 'IR_loss': tensor(73.0603, device='cuda:0', grad_fn=<AddBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "max_violation = options['optim']['max_violation']\n",
    "margin = options['optim']['margin']\n",
    "\n",
    "for i, train_data in enumerate(check_loader):\n",
    "    tmps, captions, lengths, ids= train_data\n",
    "    \n",
    "    if options['model']['name'] == 'IRSeg':\n",
    "        images, targets = tmps\n",
    "    else:\n",
    "        images = tmps\n",
    "\n",
    "    batch_size = images.size(0)\n",
    "\n",
    "    images = Variable(images)\n",
    "    targets = Variable(targets)\n",
    "    input_text = Variable(captions)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        input_text = input_text.cuda()\n",
    "\n",
    "    # losses = model(input_visual, input_text, lengths)\n",
    "    results = model(images, input_text, lengths)\n",
    "    losses = {}\n",
    "    if options['model']['name'] == 'IRMIM':\n",
    "        MIM_res = results[0]\n",
    "        losses['MIM_loss'] = utils.cal_MIM_loss(MIM_res)\n",
    "    elif options['model']['name'] == 'IRSeg':\n",
    "        Seg_res = results[0]\n",
    "        loss_func = utils.SegmentationLosses(weight=None, cuda=True).build_loss(mode='ce')\n",
    "        losses['Seg_loss'] = loss_func(Seg_res, targets.long())\n",
    "    IR_res = results[-1]\n",
    "    losses['IR_loss'] = utils.cal_IR_loss(IR_res, images.size(0), margin, max_violation=max_violation)\n",
    "    print(losses)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Seg_loss': tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'IR_loss': tensor(222.5239, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
